{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np \n",
    "from matplotlib import pyplot as plt \n",
    "import seaborn as sns \n",
    "from tqdm import tqdm \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.ensemble import RandomForestClassifier  , AdaBoostClassifier , GradientBoostingClassifier\n",
    "from sklearn.metrics import precision_score , recall_score \n",
    "import xgboost as xgb \n",
    "import pandas as pd \n",
    "import sklearn.neighbors._base\n",
    "from os import sys\n",
    "sys.modules['sklearn.neighbors.base'] = sklearn.neighbors._base\n",
    "from missingpy import MissForest \n",
    "from sklearn.metrics import confusion_matrix , ConfusionMatrixDisplay\n",
    "sns.set_style('whitegrid')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "sns.set_style('whitegrid')\n",
    "from IPython.display import display"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def details(data_sent , comments = ''):\n",
    "    if(comments):\n",
    "        print(comments)\n",
    "    sp = (data_sent.isna().sum().sum())/ data_sent.size\n",
    "    print('________________________________________________')\n",
    "    print('Sparsity in the data : {:.2f}'.format(sp))\n",
    "    num_rows = data_sent.shape\n",
    "    print('Data shape' , num_rows)\n",
    "    #display(data_sent['class'].value_counts())\n",
    "    print('Number of sources : ')\n",
    "    cl = data_sent['class'].unique()\n",
    "    for c in cl:\n",
    "        num_src = len(data_sent[data_sent['class']==c]['src_id'].unique())\n",
    "        num_obs = len(data_sent[data_sent['class']==c])\n",
    "        print(c ,' \\t ' , num_src , '\\t' , num_obs)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from features import phot_flux , en_flux , hard, powlaw_fit , bb_fit , brems_fit , intra_obs_var , inter_ob_var , info_col , phot_flux_hilim , phot_flux_lolim , en_flux_hilim , en_flux_lolim"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "feat_to_use = info_col + phot_flux + phot_flux_hilim + phot_flux_lolim + en_flux + en_flux_hilim + en_flux_lolim + powlaw_fit +bb_fit +hard+ intra_obs_var +inter_ob_var "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "df = pd.read_csv('report/data-imp-all-obs.csv' , index_col='obs_id')\n",
    "details(df)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "________________________________________________\n",
      "Sparsity in the data : 0.00\n",
      "Data shape (1728, 62)\n",
      "Number of sources : \n",
      "CV  \t  60 \t 947\n",
      "PL  \t  92 \t 293\n",
      "LX  \t  58 \t 488\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "info_col_cl = info_col +['class']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Combine Obs"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "\n",
    "df_comb = pd.DataFrame()\n",
    "for s in df['src_id'].unique()[:]:\n",
    "    temp = df[df['src_id']==s]\n",
    "    temp_id =  temp[info_col_cl]\n",
    "    temp_val = temp.drop(columns=info_col_cl)\n",
    "    temp_mean = temp_val.mean().to_frame().T\n",
    "    temp_id_top = temp_id.iloc[0:1].reset_index()\n",
    "    temp_final = pd.concat([temp_id_top , temp_mean] , axis=1).set_index('obs_id')\n",
    "    df_comb = df_comb.append(temp_final)\n",
    "details(df_comb)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "________________________________________________\n",
      "Sparsity in the data : 0.00\n",
      "Data shape (210, 62)\n",
      "Number of sources : \n",
      "CV  \t  60 \t 60\n",
      "PL  \t  92 \t 92\n",
      "LX  \t  58 \t 58\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "data_id = df_comb[info_col]\n",
    "data_label = df_comb['class']\n",
    "data_val = df_comb.drop(columns=['class']+info_col)\n",
    "data_imp_norm = df_comb.copy()\n",
    "for c in data_val.columns.to_list():\n",
    "    data_imp_norm.loc[:,c] = (data_imp_norm.loc[:,c] - data_imp_norm.loc[:,c].min()) / (data_imp_norm.loc[:,c].max() - data_imp_norm.loc[:,c].min())\n",
    "    #data_imp_norm.loc[:,c] = (data_imp_norm.loc[:,c] - data_imp_norm.loc[:,c].mean()) / (data_imp_norm.loc[:,c].std())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Cross validation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "verbose = 0\n",
    "val_acc = []\n",
    "test_acc = []\n",
    "for i in tqdm(range(10)):\n",
    "    src_list = pd.DataFrame()\n",
    "\n",
    "    x = data_imp_norm.drop(columns = info_col_cl)\n",
    "    y = data_imp_norm['class']\n",
    "    info = data_imp_norm[info_col_cl] \n",
    "    x_train , x_val , y_train , y_val , i_train , i_val = train_test_split(x , y , info , test_size=0.2 , stratify=y, random_state=9)\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=400)\n",
    "    clf.fit(x_train , y_train , sample_weight=i_train['significance'])\n",
    "    v_sc = clf.score(x_val , y_val)\n",
    "    test_sc = clf.score(x_train, y_train)\n",
    "    val_acc.append(v_sc)\n",
    "    test_acc.append(test_sc)\n",
    "    #if(verbose):\n",
    "    print(test_sc , v_sc)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 10%|█         | 1/10 [00:01<00:09,  1.04s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9702380952380952 0.6666666666666666\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 20%|██        | 2/10 [00:01<00:07,  1.12it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9702380952380952 0.6904761904761905\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 30%|███       | 3/10 [00:02<00:05,  1.18it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9702380952380952 0.6666666666666666\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 40%|████      | 4/10 [00:03<00:04,  1.22it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9702380952380952 0.6904761904761905\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 50%|█████     | 5/10 [00:04<00:04,  1.23it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9702380952380952 0.6666666666666666\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 60%|██████    | 6/10 [00:05<00:03,  1.21it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9702380952380952 0.6428571428571429\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 70%|███████   | 7/10 [00:05<00:02,  1.20it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9702380952380952 0.6666666666666666\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 80%|████████  | 8/10 [00:06<00:01,  1.17it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9702380952380952 0.6904761904761905\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 90%|█████████ | 9/10 [00:07<00:00,  1.16it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9702380952380952 0.6428571428571429\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 10/10 [00:08<00:00,  1.17it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9702380952380952 0.6904761904761905\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}