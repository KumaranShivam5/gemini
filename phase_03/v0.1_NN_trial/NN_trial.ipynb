{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "import numpy as np \n",
    "from matplotlib import pyplot as plt \n",
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "data =  pd.read_csv('all_data_compiled.csv')\n",
    "print(data)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "      index_compiled  index  class  B_B_FLUX_AP  B_B_FLUX_AP_HI  \\\n",
      "0                  0     89    1.0     0.000174        0.000182   \n",
      "1                  1    370    1.0     0.000462        0.000477   \n",
      "2                  2    645    0.0     0.000003        0.000003   \n",
      "3                  3    275    1.0     0.000002        0.000002   \n",
      "4                  4    474    0.0     0.000002        0.000002   \n",
      "...              ...    ...    ...          ...             ...   \n",
      "1466            1466    221    1.0     0.000002        0.000002   \n",
      "1467            1467    864    0.0     0.000000        0.000000   \n",
      "1468            1468    777    0.0     0.000080        0.000084   \n",
      "1469            1469    831    0.0     0.000000        0.000000   \n",
      "1470            1470    374    1.0     0.001739        0.001878   \n",
      "\n",
      "      B_B_FLUX_AP_LO  B_M_FLUX_AP  B_M_FLUX_AP_HI  B_M_FLUX_AP_LO  \\\n",
      "0           0.000166     0.000569        0.000616        0.000526   \n",
      "1           0.000444     0.005532        0.005737        0.005294   \n",
      "2           0.000002     0.000021        0.000027        0.000016   \n",
      "3           0.000002     0.000016        0.000018        0.000014   \n",
      "4           0.000002     0.000018        0.000021        0.000014   \n",
      "...              ...          ...             ...             ...   \n",
      "1466        0.000001     0.000014        0.000016        0.000012   \n",
      "1467        0.000000     0.000000        0.000000        0.000000   \n",
      "1468        0.000076     0.000446        0.000478        0.000409   \n",
      "1469        0.000000     0.000000        0.000000        0.000000   \n",
      "1470        0.001585     0.000214        0.000341        0.000085   \n",
      "\n",
      "      B_APEC_ABUND  ...  B_U_PHOTFLUX_AP_AVG  B_U_PHOTFLUX_AP_AVG_HI  \\\n",
      "0              0.0  ...             0.000635                0.001227   \n",
      "1              0.0  ...             0.003835                0.004409   \n",
      "2              0.0  ...             0.000000                0.000000   \n",
      "3              0.0  ...             0.000000                0.000011   \n",
      "4              0.0  ...             0.000027                0.000037   \n",
      "...            ...  ...                  ...                     ...   \n",
      "1466           0.0  ...             0.000035                0.000049   \n",
      "1467           0.0  ...             0.000000                0.000090   \n",
      "1468           0.0  ...             0.000200                0.000225   \n",
      "1469           0.0  ...             0.002477                0.002582   \n",
      "1470           0.0  ...             0.000000                0.003636   \n",
      "\n",
      "      B_U_PHOTFLUX_AP_AVG_LO  B_U_PHOTFLUX_AP_HI  B_U_PHOTFLUX_AP_LO  \\\n",
      "0                   0.000000            0.001227            0.000000   \n",
      "1                   0.003213            0.000838            0.000039   \n",
      "2                   0.000000            0.000089            0.000041   \n",
      "3                   0.000000            0.000015            0.000000   \n",
      "4                   0.000016            0.000037            0.000016   \n",
      "...                      ...                 ...                 ...   \n",
      "1466                0.000021            0.000081            0.000041   \n",
      "1467                0.000000            0.000000            0.000000   \n",
      "1468                0.000174            0.000163            0.000075   \n",
      "1469                0.002370            0.000000            0.000000   \n",
      "1470                0.000000            0.003636            0.000000   \n",
      "\n",
      "      B_U_VAR_INTER_INDEX  B_U_VAR_INTER_PROB  B_U_VAR_INTER_SIGMA  \\\n",
      "0                   0.625             0.74100             0.004752   \n",
      "1                   0.000             0.00000             0.000000   \n",
      "2                   0.000             0.07640             0.000077   \n",
      "3                   0.000             0.00000             0.000000   \n",
      "4                   0.000             0.00106             0.000483   \n",
      "...                   ...                 ...                  ...   \n",
      "1466                0.625             0.90500             0.001147   \n",
      "1467                0.000             0.00000             0.000000   \n",
      "1468                0.750             0.93400             0.005295   \n",
      "1469                0.000             0.32500             0.001853   \n",
      "1470                0.000             0.00000             0.000000   \n",
      "\n",
      "      B_U_VAR_INTRA_INDEX  B_U_VAR_INTRA_PROB  \n",
      "0                     0.0                0.00  \n",
      "1                     0.2                0.74  \n",
      "2                     0.0                0.00  \n",
      "3                     0.0                0.00  \n",
      "4                     0.0                0.00  \n",
      "...                   ...                 ...  \n",
      "1466                  0.0                0.00  \n",
      "1467                  0.0                0.00  \n",
      "1468                  0.0                0.00  \n",
      "1469                  0.0                0.00  \n",
      "1470                  0.0                0.00  \n",
      "\n",
      "[1471 rows x 364 columns]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "print(data.shape)\n",
    "x = data.drop(['index_compiled', 'index', 'class'],axis=1)\n",
    "print(x.shape)\n",
    "y = data['class']\n",
    "y.shape"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1471, 364)\n",
      "(1471, 361)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1471,)"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "x_np =  x.to_numpy()\n",
    "y_np =  y.to_numpy()\n",
    "x_train = x_np[:1000,:]\n",
    "y_train = y_np[:1000]\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1000, 361)\n",
      "(1000,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "def sparsity(mat):\n",
    "    m,n =  mat.shape\n",
    "    count = m*n\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            if(mat[i,j]>0):\n",
    "                count-=1\n",
    "    return count/(m*n)\n",
    "spars = sparsity(x_np)\n",
    "print('Data Sparsity :{:.2f}'.format(spars))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Data Sparsity :0.52\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def split_data(x,y,s):   \n",
    "    split = 0.7 \n",
    "    split_no = int(split*len(y))\n",
    "    x_train = x[:split_no, :]\n",
    "    y_train = y[:split_no]\n",
    "    x_test = x[split_no:, :]\n",
    "    y_test = y[split_no:]\n",
    "    return ((x_train,y_train) , (x_test ,y_test))\n",
    "\n",
    "(x_train,y_train),(x_test,y_test) = split_data(x_np, y_np, 0.8)\n",
    "print(x_train.shape ,y_train.shape)\n",
    "print(x_test.shape ,y_test.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1029, 361) (1029,)\n",
      "(442, 361) (442,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Neural Netork starts here"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import to_categorical"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "one_hot_y_train =  to_categorical(y_train)\n",
    "one_hot_y_test =  to_categorical(y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def model_gen(shape):\n",
    "\n",
    "    inputs =  keras.Input(shape=(361,))\n",
    "    dense =  layers.Dense(64, activation='relu')\n",
    "    x = dense(inputs)\n",
    "    x =  layers.BatchNormalization(axis=-1)(x)\n",
    "    #x = layers.Dropout(0.3)(x)\n",
    "    for s in shape:\n",
    "        x = layers.Dense(64, activation='relu')(x)\n",
    "    \n",
    "    outputs = layers.Dense(2 , activation='sigmoid')(x)\n",
    "    model = keras.Model(inputs=inputs , outputs=outputs , name='trial_model')\n",
    "    model.compile(\n",
    "        loss = \"categorical_crossentropy\",\n",
    "        optimizer = keras.optimizers.Adam(),\n",
    "        metrics = [\"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "model = model_gen([64,64,32,8])\n",
    "history = model.fit(x_train, one_hot_y_train, batch_size=128, epochs=40, validation_split=0.1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/40\n",
      "8/8 [==============================] - 1s 43ms/step - loss: 0.6060 - accuracy: 0.7106 - val_loss: 0.6558 - val_accuracy: 0.6602\n",
      "Epoch 2/40\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4873 - accuracy: 0.7732 - val_loss: 0.6172 - val_accuracy: 0.7379\n",
      "Epoch 3/40\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4267 - accuracy: 0.8121 - val_loss: 0.5999 - val_accuracy: 0.6990\n",
      "Epoch 4/40\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3774 - accuracy: 0.8305 - val_loss: 0.6010 - val_accuracy: 0.7573\n",
      "Epoch 5/40\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3424 - accuracy: 0.8650 - val_loss: 0.5863 - val_accuracy: 0.7282\n",
      "Epoch 6/40\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3096 - accuracy: 0.8737 - val_loss: 0.5690 - val_accuracy: 0.7961\n",
      "Epoch 7/40\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2823 - accuracy: 0.8769 - val_loss: 0.5644 - val_accuracy: 0.7282\n",
      "Epoch 8/40\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2590 - accuracy: 0.8996 - val_loss: 0.5518 - val_accuracy: 0.8641\n",
      "Epoch 9/40\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2400 - accuracy: 0.9168 - val_loss: 0.5377 - val_accuracy: 0.7864\n",
      "Epoch 10/40\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2132 - accuracy: 0.9244 - val_loss: 0.5461 - val_accuracy: 0.8058\n",
      "Epoch 11/40\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2030 - accuracy: 0.9276 - val_loss: 0.5222 - val_accuracy: 0.8058\n",
      "Epoch 12/40\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1797 - accuracy: 0.9320 - val_loss: 0.5076 - val_accuracy: 0.8058\n",
      "Epoch 13/40\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1697 - accuracy: 0.9266 - val_loss: 0.4870 - val_accuracy: 0.8155\n",
      "Epoch 14/40\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1733 - accuracy: 0.9330 - val_loss: 0.4920 - val_accuracy: 0.7767\n",
      "Epoch 15/40\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1600 - accuracy: 0.9406 - val_loss: 0.4826 - val_accuracy: 0.7864\n",
      "Epoch 16/40\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1531 - accuracy: 0.9384 - val_loss: 0.4872 - val_accuracy: 0.7961\n",
      "Epoch 17/40\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1459 - accuracy: 0.9428 - val_loss: 0.4587 - val_accuracy: 0.8447\n",
      "Epoch 18/40\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1375 - accuracy: 0.9471 - val_loss: 0.4662 - val_accuracy: 0.7961\n",
      "Epoch 19/40\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1260 - accuracy: 0.9536 - val_loss: 0.4668 - val_accuracy: 0.8252\n",
      "Epoch 20/40\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1468 - accuracy: 0.9374 - val_loss: 0.4473 - val_accuracy: 0.8155\n",
      "Epoch 21/40\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1376 - accuracy: 0.9374 - val_loss: 0.4474 - val_accuracy: 0.8155\n",
      "Epoch 22/40\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1438 - accuracy: 0.9384 - val_loss: 0.4392 - val_accuracy: 0.7961\n",
      "Epoch 23/40\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1542 - accuracy: 0.9406 - val_loss: 0.4451 - val_accuracy: 0.7961\n",
      "Epoch 24/40\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1358 - accuracy: 0.9438 - val_loss: 0.4258 - val_accuracy: 0.8155\n",
      "Epoch 25/40\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1383 - accuracy: 0.9471 - val_loss: 0.4451 - val_accuracy: 0.7670\n",
      "Epoch 26/40\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1220 - accuracy: 0.9471 - val_loss: 0.4436 - val_accuracy: 0.7961\n",
      "Epoch 27/40\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1104 - accuracy: 0.9579 - val_loss: 0.4258 - val_accuracy: 0.8252\n",
      "Epoch 28/40\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1057 - accuracy: 0.9579 - val_loss: 0.4302 - val_accuracy: 0.8155\n",
      "Epoch 29/40\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1005 - accuracy: 0.9611 - val_loss: 0.4364 - val_accuracy: 0.7961\n",
      "Epoch 30/40\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1074 - accuracy: 0.9525 - val_loss: 0.4346 - val_accuracy: 0.8155\n",
      "Epoch 31/40\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1344 - accuracy: 0.9471 - val_loss: 0.4356 - val_accuracy: 0.7961\n",
      "Epoch 32/40\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1266 - accuracy: 0.9471 - val_loss: 0.4326 - val_accuracy: 0.8058\n",
      "Epoch 33/40\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1144 - accuracy: 0.9557 - val_loss: 0.4394 - val_accuracy: 0.7961\n",
      "Epoch 34/40\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0974 - accuracy: 0.9611 - val_loss: 0.4451 - val_accuracy: 0.7961\n",
      "Epoch 35/40\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1042 - accuracy: 0.9590 - val_loss: 0.4299 - val_accuracy: 0.7961\n",
      "Epoch 36/40\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0966 - accuracy: 0.9568 - val_loss: 0.4232 - val_accuracy: 0.8252\n",
      "Epoch 37/40\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0961 - accuracy: 0.9611 - val_loss: 0.4211 - val_accuracy: 0.8350\n",
      "Epoch 38/40\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0930 - accuracy: 0.9600 - val_loss: 0.4148 - val_accuracy: 0.8544\n",
      "Epoch 39/40\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0904 - accuracy: 0.9600 - val_loss: 0.4349 - val_accuracy: 0.8350\n",
      "Epoch 40/40\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0892 - accuracy: 0.9622 - val_loss: 0.4500 - val_accuracy: 0.8252\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "def acc_score(model , y_test , x_test):\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_pred = [np.argmax(r) for r in y_pred]\n",
    "    y_test = [np.argmax(r) for r in y_test]\n",
    "    #print(y_pred)\n",
    "    correct = 0\n",
    "    total =  len(y_test)\n",
    "    for y1,y2 in zip(y_pred,y_test):\n",
    "        if(int(y1)==int(y2)):\n",
    "            correct+=1\n",
    "        else:\n",
    "            continue\n",
    "    print('correct prediction :' , correct)\n",
    "    print('total prediction :' , total)\n",
    "    print('score: ' , correct/total*100)\n",
    "    \n",
    "print('training data prediction')\n",
    "acc_score(model, one_hot_y_train, x_train)\n",
    "print('----------------------------------')\n",
    "print('test data prediciton')\n",
    "acc_score(model, one_hot_y_test, x_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "training data prediction\n",
      "correct prediction : 964\n",
      "total prediction : 1029\n",
      "score:  93.68318756073857\n",
      "----------------------------------\n",
      "test data prediciton\n",
      "correct prediction : 388\n",
      "total prediction : 442\n",
      "score:  87.78280542986425\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "res = model.predict(x_test)\n",
    "res = [np.argmax(r) for r in res]\n",
    "#print(res)\n",
    "count = 0\n",
    "for a,b in zip(res,y_test):\n",
    "    if(int(a)==int(b)):\n",
    "        count+=1\n",
    "print(count , len(y_test))\n",
    "print(count/len(y_test))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "388 442\n",
      "0.8778280542986425\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}