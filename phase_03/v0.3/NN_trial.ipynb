{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "import numpy as np \n",
    "from matplotlib import pyplot as plt \n",
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "data =  pd.read_csv('all_data_compiled_v2.csv')\n",
    "print(data)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "      index_compiled  index  class  B_M_FLUX_AP  B_B_FLUX_AP_AVG  \\\n",
      "0                  0    194    0.0     0.000222     0.000000e+00   \n",
      "1                  1    464    0.0     0.000105     0.000000e+00   \n",
      "2                  2   1496    1.0     0.000038     1.607810e-04   \n",
      "3                  3    588    0.0     0.000011     0.000000e+00   \n",
      "4                  4   1059    1.0     0.000005     8.777589e-07   \n",
      "...              ...    ...    ...          ...              ...   \n",
      "2558            2558   1418    1.0     0.000000     3.378608e-05   \n",
      "2559            2559    456    0.0     0.000021     0.000000e+00   \n",
      "2560            2560   1222    1.0     0.010319     2.393888e-02   \n",
      "2561            2561    470    1.0     0.000008     2.410866e-06   \n",
      "2562            2562    526    0.0     0.000016     1.448217e-06   \n",
      "\n",
      "      B_B_FLUX_BB_AP  B_B_FLUX_BREMS_AP  B_B_FLUX_BREMS_AP90  \\\n",
      "0           0.000088           0.000074             0.000152   \n",
      "1           0.000043           0.000037             0.000078   \n",
      "2           0.000018           0.000016             0.000035   \n",
      "3           0.000000           0.000000             0.000000   \n",
      "4           0.000002           0.000002             0.000004   \n",
      "...              ...                ...                  ...   \n",
      "2558        0.000044           0.000045             0.000098   \n",
      "2559        0.000000           0.000000             0.000000   \n",
      "2560        0.021661           0.023233             0.037578   \n",
      "2561        0.000003           0.000003             0.000006   \n",
      "2562        0.000007           0.000006             0.000013   \n",
      "\n",
      "      B_B_FLUX_PLAW_AP  B_B_FLUX_PLAW_AP90  ...  B_S_KS_INTRA_PROB  \\\n",
      "0             0.000069            0.000140  ...              1.000   \n",
      "1             0.000035            0.000073  ...              0.866   \n",
      "2             0.000016            0.000033  ...              0.700   \n",
      "3             0.000000            0.000000  ...              0.000   \n",
      "4             0.000002            0.000004  ...              0.305   \n",
      "...                ...                 ...  ...                ...   \n",
      "2558          0.000045            0.000096  ...              0.000   \n",
      "2559          0.000000            0.000000  ...              0.000   \n",
      "2560          0.023486            0.037609  ...              0.916   \n",
      "2561          0.000003            0.000006  ...              0.000   \n",
      "2562          0.000006            0.000012  ...              0.978   \n",
      "\n",
      "      B_S_PHOTFLUX_AP  B_S_PHOTFLUX_AP90  B_S_PHOTFLUX_AP90_AVG  \\\n",
      "0            0.000489           0.001913               0.003894   \n",
      "1            0.000309           0.001240               0.001490   \n",
      "2            0.000057           0.000174               0.003033   \n",
      "3            0.000013           0.000039               0.000041   \n",
      "4            0.000000           0.000000               0.000000   \n",
      "...               ...                ...                    ...   \n",
      "2558         0.000000           0.000000               0.000000   \n",
      "2559         0.000017           0.000055               0.000060   \n",
      "2560         0.000872           0.002020               0.001907   \n",
      "2561         0.000006           0.000023               0.000021   \n",
      "2562         0.000000           0.000000               0.000222   \n",
      "\n",
      "      B_S_PHOTFLUX_AP_AVG  B_S_VAR_INTER_INDEX  B_S_VAR_INTER_PROB  \\\n",
      "0                0.000621                0.500              0.6210   \n",
      "1                0.000230                0.000              0.0892   \n",
      "2                0.000480                0.000              0.4620   \n",
      "3                0.000008                0.000              0.2730   \n",
      "4                0.000000                0.625              0.8750   \n",
      "...                   ...                  ...                 ...   \n",
      "2558             0.000000                0.000              0.0000   \n",
      "2559             0.000009                0.000              0.0000   \n",
      "2560             0.000509                0.000              0.0000   \n",
      "2561             0.000003                0.625              0.7720   \n",
      "2562             0.000035                0.000              0.0000   \n",
      "\n",
      "      B_S_VAR_INTER_SIGMA  B_S_VAR_INTRA_INDEX  B_S_VAR_INTRA_PROB  \n",
      "0                0.012927                  0.1               0.504  \n",
      "1                0.008994                  0.0               0.376  \n",
      "2                0.002104                  0.0               0.000  \n",
      "3                0.009131                  0.0               0.000  \n",
      "4                0.001145                  0.0               0.472  \n",
      "...                   ...                  ...                 ...  \n",
      "2558             0.000000                  0.0               0.000  \n",
      "2559             0.000000                  0.0               0.000  \n",
      "2560             0.000000                  0.0               0.000  \n",
      "2561             0.001175                  0.0               0.000  \n",
      "2562             0.000000                  0.0               0.000  \n",
      "\n",
      "[2563 rows x 117 columns]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "print(data.shape)\n",
    "x = data.drop(['index_compiled', 'index', 'class'],axis=1)\n",
    "print(x.shape)\n",
    "y = data['class']\n",
    "y.shape"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(2563, 117)\n",
      "(2563, 114)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2563,)"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "x_np =  x.to_numpy()\n",
    "y_np =  y.to_numpy()\n",
    "x_train = x_np[:1000,:]\n",
    "y_train = y_np[:1000]\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1000, 114)\n",
      "(1000,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "def split_data(x,y,s):   \n",
    "    split = 0.7 \n",
    "    split_no = int(split*len(y))\n",
    "    x_train = x[:split_no, :]\n",
    "    y_train = y[:split_no]\n",
    "    x_test = x[split_no:, :]\n",
    "    y_test = y[split_no:]\n",
    "    return ((x_train,y_train) , (x_test ,y_test))\n",
    "\n",
    "(x_train,y_train),(x_test,y_test) = split_data(x_np, y_np, 0.8)\n",
    "print(x_train.shape ,y_train.shape)\n",
    "print(x_test.shape ,y_test.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1794, 114) (1794,)\n",
      "(769, 114) (769,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Neural Netork starts here"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import to_categorical"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "one_hot_y_train =  to_categorical(y_train)\n",
    "one_hot_y_test =  to_categorical(y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "def model_gen(shape):\n",
    "\n",
    "    inputs =  keras.Input(shape=(114,))\n",
    "    dense =  layers.Dense(64, activation='relu')\n",
    "    x = dense(inputs)\n",
    "    x =  layers.BatchNormalization(axis=-1)(x)\n",
    "    #x = layers.Dropout(0.3)(x)\n",
    "    for s in shape:\n",
    "        x = layers.Dense(64, activation='relu')(x)\n",
    "    \n",
    "    outputs = layers.Dense(2 , activation='sigmoid')(x)\n",
    "    model = keras.Model(inputs=inputs , outputs=outputs , name='trial_model')\n",
    "    model.compile(\n",
    "        loss = \"categorical_crossentropy\",\n",
    "        optimizer = keras.optimizers.Adam(),\n",
    "        metrics = [\"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "model = model_gen([64,64,32,8])\n",
    "history = model.fit(x_train, one_hot_y_train, batch_size=128, epochs=40, validation_split=0.1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/40\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 0.5713 - accuracy: 0.6772 - val_loss: 0.6341 - val_accuracy: 0.7611\n",
      "Epoch 2/40\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4654 - accuracy: 0.7763 - val_loss: 0.6132 - val_accuracy: 0.7556\n",
      "Epoch 3/40\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4073 - accuracy: 0.8185 - val_loss: 0.6073 - val_accuracy: 0.7611\n",
      "Epoch 4/40\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3631 - accuracy: 0.8463 - val_loss: 0.5861 - val_accuracy: 0.7833\n",
      "Epoch 5/40\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3253 - accuracy: 0.8662 - val_loss: 0.5665 - val_accuracy: 0.7667\n",
      "Epoch 6/40\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2932 - accuracy: 0.8835 - val_loss: 0.5476 - val_accuracy: 0.7778\n",
      "Epoch 7/40\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2755 - accuracy: 0.8767 - val_loss: 0.5518 - val_accuracy: 0.7667\n",
      "Epoch 8/40\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2580 - accuracy: 0.9015 - val_loss: 0.5327 - val_accuracy: 0.7500\n",
      "Epoch 9/40\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2286 - accuracy: 0.9108 - val_loss: 0.5215 - val_accuracy: 0.7389\n",
      "Epoch 10/40\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2282 - accuracy: 0.8984 - val_loss: 0.5235 - val_accuracy: 0.7556\n",
      "Epoch 11/40\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2078 - accuracy: 0.9176 - val_loss: 0.4957 - val_accuracy: 0.7611\n",
      "Epoch 12/40\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1902 - accuracy: 0.9182 - val_loss: 0.5002 - val_accuracy: 0.7389\n",
      "Epoch 13/40\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1919 - accuracy: 0.9157 - val_loss: 0.4237 - val_accuracy: 0.8389\n",
      "Epoch 14/40\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1833 - accuracy: 0.9188 - val_loss: 0.4139 - val_accuracy: 0.8389\n",
      "Epoch 15/40\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1890 - accuracy: 0.9120 - val_loss: 0.4285 - val_accuracy: 0.8222\n",
      "Epoch 16/40\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1668 - accuracy: 0.9343 - val_loss: 0.4044 - val_accuracy: 0.8333\n",
      "Epoch 17/40\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1751 - accuracy: 0.9263 - val_loss: 0.3855 - val_accuracy: 0.8444\n",
      "Epoch 18/40\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1663 - accuracy: 0.9287 - val_loss: 0.4158 - val_accuracy: 0.8167\n",
      "Epoch 19/40\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1580 - accuracy: 0.9306 - val_loss: 0.3658 - val_accuracy: 0.8389\n",
      "Epoch 20/40\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1665 - accuracy: 0.9294 - val_loss: 0.3828 - val_accuracy: 0.8333\n",
      "Epoch 21/40\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1564 - accuracy: 0.9380 - val_loss: 0.3593 - val_accuracy: 0.8333\n",
      "Epoch 22/40\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1701 - accuracy: 0.9294 - val_loss: 0.3760 - val_accuracy: 0.8278\n",
      "Epoch 23/40\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1729 - accuracy: 0.9226 - val_loss: 0.3567 - val_accuracy: 0.8333\n",
      "Epoch 24/40\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1537 - accuracy: 0.9349 - val_loss: 0.3696 - val_accuracy: 0.8444\n",
      "Epoch 25/40\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1499 - accuracy: 0.9275 - val_loss: 0.3738 - val_accuracy: 0.8333\n",
      "Epoch 26/40\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1450 - accuracy: 0.9362 - val_loss: 0.3485 - val_accuracy: 0.8556\n",
      "Epoch 27/40\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1400 - accuracy: 0.9368 - val_loss: 0.3815 - val_accuracy: 0.8333\n",
      "Epoch 28/40\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1435 - accuracy: 0.9294 - val_loss: 0.3951 - val_accuracy: 0.8444\n",
      "Epoch 29/40\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1492 - accuracy: 0.9287 - val_loss: 0.3619 - val_accuracy: 0.8556\n",
      "Epoch 30/40\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1545 - accuracy: 0.9195 - val_loss: 0.3626 - val_accuracy: 0.8500\n",
      "Epoch 31/40\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1433 - accuracy: 0.9349 - val_loss: 0.4040 - val_accuracy: 0.8500\n",
      "Epoch 32/40\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1464 - accuracy: 0.9343 - val_loss: 0.3492 - val_accuracy: 0.8556\n",
      "Epoch 33/40\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1458 - accuracy: 0.9257 - val_loss: 0.3526 - val_accuracy: 0.8667\n",
      "Epoch 34/40\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1509 - accuracy: 0.9387 - val_loss: 0.3668 - val_accuracy: 0.8556\n",
      "Epoch 35/40\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1399 - accuracy: 0.9337 - val_loss: 0.3855 - val_accuracy: 0.8556\n",
      "Epoch 36/40\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1404 - accuracy: 0.9349 - val_loss: 0.3769 - val_accuracy: 0.8611\n",
      "Epoch 37/40\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1368 - accuracy: 0.9325 - val_loss: 0.3971 - val_accuracy: 0.8667\n",
      "Epoch 38/40\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1326 - accuracy: 0.9362 - val_loss: 0.3793 - val_accuracy: 0.8611\n",
      "Epoch 39/40\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1358 - accuracy: 0.9393 - val_loss: 0.4096 - val_accuracy: 0.8611\n",
      "Epoch 40/40\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1315 - accuracy: 0.9380 - val_loss: 0.4567 - val_accuracy: 0.8611\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "def acc_score(model , y_test , x_test):\n",
    "    y_pred = model.predict(x_test)\n",
    "    correct = 0\n",
    "    total =  len(y_test)\n",
    "    for y1,y2 in zip(y_pred,y_test):\n",
    "        if(int(y1)==int(y2)):\n",
    "            correct+=1\n",
    "        else:\n",
    "            continue\n",
    "    print('correct prediction :' , correct)\n",
    "    print('total prediction :' , total)\n",
    "    print('score: ' , correct/total*100)\n",
    "    \n",
    "print('training data prediction')\n",
    "acc_score(model, one_hot_y_train, x_train)\n",
    "print('----------------------------------')\n",
    "print('test data prediciton')\n",
    "acc_score(model, y_test, x_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "training data prediction\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "only size-1 arrays can be converted to Python scalars",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-c0c3e7d7527a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'training data prediction'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0macc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_hot_y_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'----------------------------------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test data prediciton'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-c0c3e7d7527a>\u001b[0m in \u001b[0;36macc_score\u001b[0;34m(model, y_test, x_test)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0mcorrect\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "res = model.predict(x_test)\n",
    "res = [np.argmax(r) for r in res]\n",
    "print(res)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "count = 0\n",
    "for a,b in zip(res,y_test):\n",
    "    if(int(a)==int(b)):\n",
    "        count+=1\n",
    "print(count , len(y_test))\n",
    "print(count/len(y_test))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "667 769\n",
      "0.8673602080624188\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}